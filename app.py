import streamlit as st
import os
import time
import logging

# ModÃ¼llerimiz
from src.ingestion import load_documents, split_documents
from src.vector_store import create_vector_db
from src.rag_chain import get_rag_chain
from src.utils import get_user_dirs, clear_user_data

# LOG AYARI
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

st.set_page_config(
    page_title="Vektra AI | Kurumsal HafÄ±za",
    page_icon="assets/logo.png", # Logonun "assets" klasÃ¶rÃ¼nde olduÄŸunu varsayÄ±yoruz
    layout="wide"
)

user_source_dir, user_vector_db_dir = get_user_dirs()

if os.path.exists("assets/logo.png"):
    st.image("assets/logo.png", width=100)

st.title("Vektra AI - Kurumsal Asistan")
st.markdown(
    """
    Bu asistan, yÃ¼klediÄŸiniz **PDF, Word, Excel ve CSV** dosyalarÄ±nÄ± okur, analiz eder 
    ve sorularÄ±nÄ±za **dokÃ¼manlara dayanarak** cevap verir.
    """
)

# YAN MENÃœ 
with st.sidebar:
    if os.path.exists("assets/logo.png"):
        st.image("assets/logo.png", use_column_width=True)
        
    st.header("ğŸ“‚ DokÃ¼man YÃ¶netimi")
    st.info(f"Oturum ID: {os.path.basename(user_source_dir)}") # Debug iÃ§in ID gÃ¶sterelim
    
    uploaded_files = st.file_uploader(
        "PDF, Word, Excel veya CSV yÃ¼kleyin",
        accept_multiple_files=True,
        type=["pdf", "docx", "csv", "xlsx"]
    )
    
    col1, col2 = st.columns(2)
    
    with col1:
        process_btn = st.button("ğŸš€ Verileri Ä°ÅŸle")
        
    with col2:
        if st.button("ğŸ—‘ï¸ Temizle"):
            clear_user_data()
            st.success("HafÄ±za temizlendi!")
            time.sleep(1)
            st.rerun()

    # Ä°ÅLEME BUTONU MANTIÄI
    if process_btn and uploaded_files:
        with st.spinner("DokÃ¼manlar analiz ediliyor... â³"):
            try:
                
                if not os.path.exists(user_source_dir):
                    os.makedirs(user_source_dir)

                # 2. DosyalarÄ± Kaydet
                for uploaded_file in uploaded_files:
                    file_path = os.path.join(user_source_dir, uploaded_file.name)
                    with open(file_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                
                # 3. Ingestion (Okuma & ParÃ§alama)
                st.text("ğŸ“„ Dosyalar okunuyor...")
                docs = load_documents(user_source_dir)
                chunks = split_documents(docs)
                
                # 4. Vector Store (Kaydetme)
                st.text("ğŸ§  Bilgiler vektÃ¶rlere Ã§evriliyor...")
                create_vector_db(chunks, user_vector_db_dir)
                
                st.success(f"âœ… {len(uploaded_files)} dosya baÅŸarÄ±yla Ã¶ÄŸrenildi!")
                
            except Exception as e:
                st.error(f"Hata oluÅŸtu: {e}")
                logger.error(f"UI Error: {e}", exc_info=True)

# CHAT EKRANI

# Sohbet geÃ§miÅŸini baÅŸlat
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "Merhaba! YÃ¼klediÄŸiniz dokÃ¼manlarla ilgili ne bilmek istersiniz?"}
    ]

# MesajlarÄ± ekrana bas
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# KullanÄ±cÄ±dan soru al
if prompt := st.chat_input("Sorunuzu buraya yazÄ±n..."):
    
    # KullanÄ±cÄ± mesajÄ±nÄ± gÃ¶ster
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
        
    # AI CevabÄ±
    with st.chat_message("assistant"):
        with st.spinner("Cevap aranÄ±yor..."):
            try:
                # KullanÄ±cÄ±nÄ±n Ã–ZEL veritabanÄ±nÄ± kullanarak zinciri kur
                qa_chain = get_rag_chain(user_vector_db_dir)
                
                if qa_chain:
                    response = qa_chain.invoke({"query": prompt})
                    result = response['result']
                    
                    # KaynaklarÄ± topla
                    sources = [os.path.basename(doc.metadata.get('source', '')) for doc in response['source_documents']]
                    sources = list(set(sources))
                    
                    st.markdown(result)
                    
                    if sources:
                        st.caption(f"ğŸ“š Kaynaklar: {', '.join(sources)}")
                        
                    st.session_state.messages.append({"role": "assistant", "content": result})
                else:
                    st.warning("âš ï¸ LÃ¼tfen Ã¶nce sol taraftan dokÃ¼man yÃ¼kleyip 'Verileri Ä°ÅŸle' butonuna basÄ±n.")
                    
            except Exception as e:
                logger.error(f"Chat Error: {e}", exc_info=True)
                st.error("Bir sorun oluÅŸtu. LÃ¼tfen dokÃ¼man yÃ¼klediÄŸinizden emin olun.")