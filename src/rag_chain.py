import logging
import os
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from src.vector_store import load_vector_db
from src.config import Config

# 1. LOGGING AYARLARI
log_dir = "logs"
if not os.path.exists(log_dir):
    os.makedirs(log_dir)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(os.path.join(log_dir, "rag_chain.log"), encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def get_rag_chain(vector_db_path: str):
    """
    RAG zincirini oluÅŸturur.
    Args:
        vector_db_path (str): KullanÄ±cÄ±ya Ã¶zel vektÃ¶r veritabanÄ± yolu.
    """
    try:
        # A) HafÄ±zayÄ± YÃ¼kle 
        logger.info(f"ğŸ§  HafÄ±za yÃ¼kleniyor: {vector_db_path}")
        vector_store = load_vector_db(vector_db_path)
        
        if not vector_store:
            logger.error("âŒ VektÃ¶r veritabanÄ± yÃ¼klenemedi!")
            return None
            
        retriever = vector_store.as_retriever(search_kwargs={"k": 3})

        # B) ZekayÄ± HazÄ±rla
        logger.info(f"ğŸ¤– Yapay Zeka Modeli hazÄ±rlanÄ±yor: {Config.LLM_MODEL_NAME}")
        llm = ChatGoogleGenerativeAI(
            model=Config.LLM_MODEL_NAME,
            google_api_key=Config.GOOGLE_API_KEY,
            temperature=0.3
        )

        # C) Prompt HazÄ±rla
        prompt_template = """
        Sen kurumsal bir asistansÄ±n. AÅŸaÄŸÄ±daki baÄŸlamÄ± (context) kullanarak soruyu cevapla.
        EÄŸer cevap baÄŸlamda yoksa, "Bu konuda bilgim yok" de, uydurma.
        
        BaÄŸlam:
        {context}

        Soru:
        {question}

        Cevap:
        """
        PROMPT = PromptTemplate(template=prompt_template, input_variables=["context", "question"])

        # D) Zinciri Kur
        logger.info("ğŸ”— RAG Zinciri oluÅŸturuluyor...")
        chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=retriever,
            return_source_documents=True,
            chain_type_kwargs={"prompt": PROMPT}
        )
        
        return chain

    except Exception as e:
        logger.error(f"âŒ RAG Zinciri hatasÄ±: {e}")
        return None

if __name__ == "__main__":
    # TEST SENARYOSU
    logger.info("ğŸ§ª --- CHATBOT TESTÄ° BAÅLIYOR ---")
    
    test_db_path = "faiss_index_test" 
    
    qa_chain = get_rag_chain(test_db_path)
    
    if qa_chain:
        soru = "Bu dokÃ¼man ne hakkÄ±nda?"
        logger.info(f"â“ Soru: {soru}")
        
        response = qa_chain.invoke({"query": soru})
        
        print("\n" + "="*50)
        print(f"ğŸ¤– CEVAP:\n{response['result']}")
        print("="*50 + "\n")
        
        print("ğŸ“š Kaynaklar:")
        for doc in response['source_documents']:
            print(f"- {doc.metadata.get('source', 'Bilinmeyen Kaynak')}")
            
    logger.info("ğŸ --- TEST BÄ°TÄ°ÅÄ° ---")